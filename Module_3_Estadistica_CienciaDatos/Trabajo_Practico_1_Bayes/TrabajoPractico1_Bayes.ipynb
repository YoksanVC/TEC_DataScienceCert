{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Practico 1: Bayes Ingenuo\n",
    "\n",
    "### Estudiantes:\n",
    "1. Sophia Contreras\n",
    "2. Yoksan Varela\n",
    "3. Mauro Viquez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias usadas en el codigo\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_dataset(is_train = True):\n",
    "    \"\"\"Funcion para cargar CIFAR10 dataset\n",
    "\n",
    "    Args:\n",
    "        is_train (bool, optional): Especifica si el modelo se esta entrenando. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Retorna los tensores con sus respectivos labels\n",
    "    \"\"\"\n",
    "    # Define a transformation to convert images to grayscale\n",
    "    transforms_1 = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Grayscale(num_output_channels=1)  # Convert to grayscale\n",
    "    ])\n",
    "    cifar_trainset = datasets.CIFAR10(root='./data', train = is_train, download = True, transform = transforms_1)\n",
    "  \n",
    "\n",
    "    # Initialize an empty list to store batches\n",
    "    all_data = []\n",
    "    train_loader = torch.utils.data.DataLoader(cifar_trainset, batch_size = 64, shuffle=True)\n",
    "    # Iterate over the train_loader to fetch all batches\n",
    "    for batch in train_loader:\n",
    "        images, _ = batch  # Extract images from the batch\n",
    "        all_data.append(images)\n",
    "\n",
    "    # Concatenate all batches into a single tensor along the batch dimension\n",
    "    cifar_trainset_tensor = torch.round(torch.cat(all_data, dim=0) * 255)\n",
    "    cifar_labels = torch.tensor(cifar_trainset.targets)\n",
    "    print(\"cifar_trainset_tensor shape \", cifar_trainset_tensor.shape)\n",
    "    print(\"cifar_labels \", cifar_labels.shape)\n",
    "    return (cifar_trainset_tensor, cifar_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:18<00:00, 9079266.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "cifar_trainset_tensor shape  torch.Size([50000, 1, 32, 32])\n",
      "cifar_labels  torch.Size([50000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[129., 128., 126.,  ..., 138., 137., 139.],\n",
       "           [141., 139., 138.,  ..., 152., 149., 150.],\n",
       "           [144., 139., 138.,  ..., 154., 148., 148.],\n",
       "           ...,\n",
       "           [231., 231., 236.,  ...,  62.,  36.,  58.],\n",
       "           [236., 240., 240.,  ...,  96.,  53.,  55.],\n",
       "           [236., 230., 225.,  ..., 115.,  78.,  57.]]],\n",
       " \n",
       " \n",
       "         [[[170., 165., 178.,  ..., 217., 218., 204.],\n",
       "           [169., 162., 173.,  ..., 198., 202., 168.],\n",
       "           [164., 158., 165.,  ..., 164., 143., 168.],\n",
       "           ...,\n",
       "           [119., 119., 119.,  ..., 143., 144., 145.],\n",
       "           [119., 120., 120.,  ..., 143., 144., 145.],\n",
       "           [117., 117., 115.,  ..., 140., 140., 141.]]],\n",
       " \n",
       " \n",
       "         [[[155., 120., 135.,  ..., 148., 154., 169.],\n",
       "           [149., 113., 154.,  ..., 140., 147., 147.],\n",
       "           [147., 126., 156.,  ..., 155., 159., 166.],\n",
       "           ...,\n",
       "           [191., 182., 174.,  ..., 167., 164., 158.],\n",
       "           [182., 165., 163.,  ..., 158., 157., 159.],\n",
       "           [193., 167., 145.,  ..., 168., 160., 162.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[145., 177., 141.,  ..., 175., 157., 124.],\n",
       "           [118., 150., 136.,  ..., 159., 155., 131.],\n",
       "           [120., 130., 135.,  ..., 139., 145., 137.],\n",
       "           ...,\n",
       "           [116.,  94.,  81.,  ...,  95.,  97.,  95.],\n",
       "           [ 84.,  97., 116.,  ...,  96.,  97.,  84.],\n",
       "           [ 69., 117., 118.,  ...,  96., 103.,  98.]]],\n",
       " \n",
       " \n",
       "         [[[ 39.,  41.,  77.,  ..., 135., 165., 192.],\n",
       "           [ 41.,  40.,  55.,  ..., 141., 153., 144.],\n",
       "           [ 55.,  28.,  44.,  ..., 142., 134.,  78.],\n",
       "           ...,\n",
       "           [ 31.,  44.,  46.,  ...,  67.,  53.,  60.],\n",
       "           [ 81.,  44.,  27.,  ...,  93.,  43.,  48.],\n",
       "           [119.,  49.,  35.,  ...,  54.,  46.,  67.]]],\n",
       " \n",
       " \n",
       "         [[[ 74.,  77., 104.,  ...,  80.,  75.,  77.],\n",
       "           [ 73.,  79., 128.,  ...,  84.,  85.,  86.],\n",
       "           [ 91.,  95., 117.,  ...,  93.,  90.,  81.],\n",
       "           ...,\n",
       "           [ 81.,  80.,  70.,  ...,  68.,  74.,  85.],\n",
       "           [ 82.,  86.,  76.,  ...,  95.,  91., 117.],\n",
       "           [ 67.,  90.,  78.,  ...,  96.,  97., 115.]]]]),\n",
       " tensor([6, 9, 9,  ..., 9, 1, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargando el dataset CIFAR10\n",
    "load_cifar10_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_cifar10_dataset.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
